# ğŸš Drone Reinforcement Learning with CoppeliaSim + Stable-Baselines3

This project implements **reinforcement learning (RL)** for a drone (quadcopter) in a simulated 3D environment using **CoppeliaSim** and **Stable-Baselines3**. The drone learns to reach a goal position while avoiding obstacles and maintaining flight stability.

![Training Overview](https://your-image-or-demo-link.com) <!-- Optional: Add a gif or image demo -->

---

## ğŸ“¦ Features

- âœ… **CoppeliaSim Remote Control** via ZMQ API
- âœ… Custom Gym-compatible drone environment
- âœ… **PPO** algorithm from Stable-Baselines3
- âœ… Episode logging and automatic checkpointing
- âœ… Real-time training plots for metrics and reward
- âœ… Handles crashing, hovering, and stuck detection

---

## ğŸ”§ Requirements

- Python 3.7â€“3.10  
- [CoppeliaSim](https://www.coppeliarobotics.com/)  
- [ZMQ Remote API for CoppeliaSim](https://github.com/CoppeliaRobotics/zmqRemoteApi)

### Install Python Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ Getting Started

### 1. Setup CoppeliaSim

- Open CoppeliaSim and load a scene that contains:
  - A drone (named `/Drone`)
  - A target dummy (`/TargetDummy`)
  - Optional obstacle blocks (`/ConcretBlock[0-15]`)
- Ensure **ZMQ Remote API** is enabled in CoppeliaSim.

### 2. Train the Drone

```bash
python train.py
```

Training will:
- Start or resume learning from the last checkpoint
- Save models every 5000 steps to `checkpoints/`
- Log episode stats to `training_log.csv`

You can interrupt training anytime with `Ctrl+C`.

---

## ğŸ“ˆ Visualizing Progress

To visualize training stats:

```bash
python -c "from drone_env import plot_training_log; plot_training_log()"
```

You'll see:
- Episode rewards
- Distance to target
- Final altitude
- Hover drift and stability
- Stuck/crash events

---

## ğŸ§  How It Works

The drone agent receives:
- Relative position and velocity to the target
- Orientation and angular velocity

It learns to:
- Reach the target
- Avoid crashing
- Maintain stable flight
- Not get stuck

Rewards are shaped to encourage efficient, safe, and smooth flying.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ train.py              # Main RL training script
â”œâ”€â”€ drone_env.py          # Custom environment (Gym + CoppeliaSim)
â”œâ”€â”€ checkpoints/          # Auto-saved models
â”œâ”€â”€ training_log.csv      # Episode stats
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # You're here!
```

---

## ğŸ”® Possible Extensions

- Add curriculum learning
- Apply domain randomization for sim2real
- Test with different RL algorithms (SAC, TD3)
- Export for use with real drones (e.g., PX4, MAVSDK)

---

## ğŸ“œ License

MIT License Â© [Your Name](https://github.com/yourusername)

---

## ğŸ™Œ Acknowledgments

- [CoppeliaSim by Coppelia Robotics](https://www.coppeliarobotics.com/)
- [Stable-Baselines3](https://github.com/DLR-RM/stable-baselines3)


